{"version":3,"sources":["utils.js","components/VideoCamera/VideoCamera.js","components/VideoCamera/useUserMedia.js","App.js","reportWebVitals.js","index.js"],"names":["drawEmoticon","ctx","x","y","scale","emoticon","beginPath","arc","Math","PI","fillText","drawEmoticons","pose","video","videoWidth","videoHeight","canvas","emoticons","current","getContext","filteredResult","getFilteredBodyparts","keypoints","width","height","minConfidence","font","textAlign","i","length","keypoint","score","position","drawTextPoints","bodyparts","reduce","filtered","option","Object","keys","includes","part","push","VideoCamera","videoRef","constraints","useState","stream","setStream","error","setError","status","setStatus","useEffect","canceled","navigator","mediaDevices","getUserMedia","then","useUserMedia","srcObject","setAttribute","play","message","ref","INPUT_RESOLUTION","EMOTICONS","nose","leftEye","rightEye","leftEar","rightEar","App","facingMode","setFacingMode","webcamEl","useRef","canvasEl","handleCameraClick","useCallback","mediaStream","getTracks","forEach","track","stop","removeTrack","stopAndRemoveTrack","clearRect","detectPose","posenet_model","a","readyState","camera","estimateSinglePose","posenet","inputResolution","model","setInterval","initPoseNet","className","onClick","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"mXAqBA,SAASA,EAAaC,EAAKC,EAAGC,EAAGC,EAAOC,GAEtCJ,EAAIK,YACJL,EAAIM,IAAIL,EAAIE,EAAOD,EAAIC,EAAO,EAAG,EAAG,EAAII,KAAKC,IAC7CR,EAAIS,SAASL,EAAUH,EAAGC,GAGrB,SAASQ,EACdC,EACAC,EACAC,EACAC,EACAC,EACAC,GAEA,IAAMhB,EAAMe,EAAOE,QAAQC,WAAW,MAChCC,EAAiBC,EAAqBT,EAAKU,UAAWL,GAE5DD,EAAOE,QAAQK,MAAQT,EACvBE,EAAOE,QAAQM,OAAST,EArCnB,SAAwBO,EAAWG,EAAexB,GAAiB,IAAZG,EAAW,uDAAH,EACpEH,EAAIyB,KAAO,aACXzB,EAAI0B,UAAY,SAEhB,IAAK,IAAIC,EAAI,EAAGA,EAAIN,EAAUO,OAAQD,IAAK,CACzC,IAAME,EAAWR,EAAUM,GAE3B,KAAIE,EAASC,MAAQN,GAArB,CAHyC,MAOxBK,EAASE,SAAlB7B,EAPiC,EAOjCA,EAGRH,EAAaC,EAV4B,EAO9BC,EAGUC,EAAGC,EAAO0B,EAASzB,YAyB1C4B,CAAeb,EAAgB,GAAKnB,EAAK,GAcpC,IAAMoB,EAAuB,SAACC,EAAWY,GAAZ,OAClCZ,EAAUa,QAAO,SAACC,EAAUC,GAO1B,OANIC,OAAOC,KAAKL,GAAWM,SAASH,EAAOI,OACzCL,EAASM,KAAT,2BACKL,GADL,IAEEhC,SAAU6B,EAAUG,EAAOI,SAGxBL,IACN,K,OCjCUO,MA7Bf,YAAiD,IAA1BC,EAAyB,EAAzBA,SAAyB,ECDjC,SAAsBC,GAAc,IAAD,EACpBC,qBADoB,mBACzCC,EADyC,KACjCC,EADiC,OAEtBF,qBAFsB,mBAEzCG,EAFyC,KAElCC,EAFkC,OAGpBJ,mBAAS,WAHW,mBAGzCK,EAHyC,KAGjCC,EAHiC,KA4BhD,OAvBAC,qBAAU,WACR,IAAIC,GAAW,EAiBf,OAhBAF,EAAU,WACVG,UAAUC,aAAaC,aAAaZ,GAAaa,MAC/C,SAACX,GACMO,IACHF,EAAU,YACVJ,EAAUD,OAGd,SAACE,GACMK,IACHF,EAAU,SACVF,EAASD,OAKR,WACLK,GAAW,KAEZ,CAACT,IAEG,CAAEI,QAAOE,SAAQJ,UD1BUY,CADY,EAAfd,aACvBI,EADsC,EACtCA,MAAOE,EAD+B,EAC/BA,OAAQJ,EADuB,EACvBA,OAiBvB,OAfAM,qBAAU,WACR,GAAe,aAAXF,GAA0BJ,EAA9B,CAIA,IAAMlC,EAAQ+B,EAAS1B,QACvBL,EAAM+C,UAAYb,EAGlBlC,EAAMgD,aAAa,eAAe,GAClChD,EAAMgD,aAAa,YAAY,GAE/BhD,EAAMiD,UACL,CAACf,IAEW,YAAXI,EACK,4BAAI,eAGE,UAAXA,EACK,4BAAIF,EAAMc,UAGZ,uBAAOC,IAAKpB,KEffqB,EAAmB,CAAE1C,MAAO,IAAKC,OAAQ,KAEzC0C,EAAY,CAChBC,KAAM,eACNC,QAAS,eACTC,SAAU,eACVC,QAAS,eACTC,SAAU,gBAiEGC,MA9Df,WAAgB,IAAD,EACuB1B,mBAAS,QADhC,mBACN2B,EADM,KACMC,EADN,KAEPC,EAAWC,iBAAO,MAClBC,EAAWD,iBAAO,MAElBE,EAAoBC,uBAAY,WHkEjC,IAAyBC,EA/CJhE,GA+CIgE,EGjEZH,EAAS3D,QAAQ0C,YHsEnCoB,EAAYC,YAAYC,QAZ1B,SAA4BF,GAC1B,OAAO,SAAUG,GACfA,EAAMC,OACNJ,EAAYK,YAAYF,IASMG,CAAmBN,KApDzBhE,EGjBZ6D,EAAS3D,SHkBJC,WAAW,MAC1BoE,UAAU,EAAG,EAAGvE,EAAOO,MAAOP,EAAOQ,QGlBvCkD,EAA6B,gBAAfD,EAA+B,OAAS,iBACrD,CAACA,IAEEe,EAAU,uCAAG,WAAOC,GAAP,mBAAAC,EAAA,yDACQ,OAArBf,EAASzD,SAAoD,IAAhCyD,EAASzD,QAAQyE,WADjC,wBAETC,EAASjB,EAASzD,QAClBJ,EAAa6D,EAASzD,QAAQJ,WAC9BC,EAAc4D,EAASzD,QAAQH,YAErC4D,EAASzD,QAAQK,MAAQT,EACzB6D,EAASzD,QAAQM,OAAST,EAPX,SAUO0E,EAAcI,mBAAmBD,GAVxC,OAWfjF,EAXe,OAabiF,EACA9E,EACAC,EACA8D,EACAX,GAjBa,4CAAH,sDAmChB,OAbiB,uCAAG,4BAAAwB,EAAA,sEACEI,IAAa,CAC/BC,gBAAiB9B,EACjB7D,MA7CQ,KA0CQ,OACZ4F,EADY,OAMlBC,aAAY,WACVT,EAAWQ,KAnDI,KA4CC,2CAAH,oDAWjBE,GAGE,sBAAKC,UAAU,MAAf,UACE,cAAC,EAAD,CACEvD,SAAU+B,EACV9B,YAAa,CACXhC,MAAO,CACL4D,iBAIN,wBAAQT,IAAKa,IACb,wBAAQuB,QAAStB,EAAjB,8BCrESuB,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqB7C,MAAK,YAAkD,IAA/C8C,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCDdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1BZ,M","file":"static/js/main.75002921.chunk.js","sourcesContent":["/**\n * Draw pose keypoints onto a canvas\n */\nexport function drawTextPoints(keypoints, minConfidence, ctx, scale = 1) {\n  ctx.font = \"16px Arial\";\n  ctx.textAlign = \"center\";\n\n  for (let i = 0; i < keypoints.length; i++) {\n    const keypoint = keypoints[i];\n\n    if (keypoint.score < minConfidence) {\n      continue;\n    }\n\n    const { y, x } = keypoint.position;\n\n    // Draws the text/emoticons on the keypoints\n    drawEmoticon(ctx, x, y, scale, keypoint.emoticon);\n  }\n}\n\nfunction drawEmoticon(ctx, x, y, scale, emoticon) {\n  // Draws the text/emoticons on the keypoints\n  ctx.beginPath();\n  ctx.arc(x * scale, y * scale, 3, 0, 2 * Math.PI);\n  ctx.fillText(emoticon, x, y);\n}\n\nexport function drawEmoticons(\n  pose,\n  video,\n  videoWidth,\n  videoHeight,\n  canvas,\n  emoticons\n) {\n  const ctx = canvas.current.getContext(\"2d\");\n  const filteredResult = getFilteredBodyparts(pose.keypoints, emoticons);\n\n  canvas.current.width = videoWidth;\n  canvas.current.height = videoHeight;\n\n  drawTextPoints(filteredResult, 0.9, ctx, 1);\n}\n\n/**\n * Clears the canvas\n */\nexport function clearCanvas(canvas) {\n  const ctx = canvas.getContext(\"2d\");\n  ctx.clearRect(0, 0, canvas.width, canvas.height);\n}\n\n/**\n * Get filtered bodyparts\n */\nexport const getFilteredBodyparts = (keypoints, bodyparts) =>\n  keypoints.reduce((filtered, option) => {\n    if (Object.keys(bodyparts).includes(option.part)) {\n      filtered.push({\n        ...option,\n        emoticon: bodyparts[option.part],\n      });\n    }\n    return filtered;\n  }, []);\n\n/**\n * Sets active camera contraints\n * @todo create seperate fuctions for updating camera and getting contraints\n */\nexport function getConstraints(camera) {\n  if (camera) {\n    return {\n      audio: false,\n      video: camera,\n    };\n  }\n\n  return {\n    audio: false,\n    video: {\n      facingMode: \"user\",\n    },\n  };\n}\n\n// taken from https://github.com/bsonntag/stop-media-stream/blob/main/index.js\nfunction stopAndRemoveTrack(mediaStream) {\n  return function (track) {\n    track.stop();\n    mediaStream.removeTrack(track);\n  };\n}\n\nexport function stopMediaStream(mediaStream) {\n  if (!mediaStream) {\n    return;\n  }\n\n  mediaStream.getTracks().forEach(stopAndRemoveTrack(mediaStream));\n}\n","import { useEffect } from \"react\";\nimport useUserMedia from \"./useUserMedia\";\n\nfunction VideoCamera({ videoRef, constraints }) {\n  const { error, status, stream } = useUserMedia(constraints);\n\n  useEffect(() => {\n    if (status !== \"resolved\" || !stream) {\n      return;\n    }\n\n    const video = videoRef.current;\n    video.srcObject = stream;\n\n    // Required for IOS\n    video.setAttribute(\"playsinline\", true);\n    video.setAttribute(\"autoplay\", true);\n\n    video.play();\n  }, [stream]);\n\n  if (status === \"pending\") {\n    return <p>{\"Loading...\"}</p>;\n  }\n\n  if (status === \"error\") {\n    return <p>{error.message}</p>;\n  }\n\n  return <video ref={videoRef} />;\n}\n\nexport default VideoCamera;\n","import { useEffect, useState } from \"react\";\n\nexport default function useUserMedia(constraints) {\n  const [stream, setStream] = useState();\n  const [error, setError] = useState();\n  const [status, setStatus] = useState(\"pending\");\n\n  useEffect(() => {\n    let canceled = false;\n    setStatus(\"pending\");\n    navigator.mediaDevices.getUserMedia(constraints).then(\n      (stream) => {\n        if (!canceled) {\n          setStatus(\"resolved\");\n          setStream(stream);\n        }\n      },\n      (error) => {\n        if (!canceled) {\n          setStatus(\"error\");\n          setError(error);\n        }\n      }\n    );\n\n    return () => {\n      canceled = true;\n    };\n  }, [constraints]);\n\n  return { error, status, stream };\n}\n","import { useRef, useState, useCallback } from \"react\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as posenet from \"@tensorflow-models/posenet\";\nimport { clearCanvas, stopMediaStream, drawEmoticons } from \"./utils\";\n\nimport \"./App.css\";\nimport VideoCamera from \"./components/VideoCamera/VideoCamera\";\n\n// TODOS\n// - Use native camera resolution as input resolution for posenet\n// - Only show switch camera button if there are multiple cameras\n\n// App consts\nconst REFRESH_RATE = 500;\nconst INPUT_RESOLUTION = { width: 640, height: 480 };\nconst SCALE = 0.8;\nconst EMOTICONS = {\n  nose: \"ðŸ””\",\n  leftEye: \"â¤ï¸\",\n  rightEye: \"â¤ï¸\",\n  leftEar: \"ðŸ’¡\",\n  rightEar: \"ðŸ’¡\",\n};\n\nfunction App() {\n  const [facingMode, setFacingMode] = useState(\"user\");\n  const webcamEl = useRef(null);\n  const canvasEl = useRef(null);\n\n  const handleCameraClick = useCallback(() => {\n    stopMediaStream(canvasEl.current.srcObject);\n    clearCanvas(canvasEl.current);\n    setFacingMode(facingMode === \"environment\" ? \"user\" : \"environment\");\n  }, [facingMode]);\n\n  const detectPose = async (posenet_model) => {\n    if (webcamEl.current !== null && webcamEl.current.readyState === 4) {\n      const camera = webcamEl.current;\n      const videoWidth = webcamEl.current.videoWidth;\n      const videoHeight = webcamEl.current.videoHeight;\n\n      webcamEl.current.width = videoWidth;\n      webcamEl.current.height = videoHeight;\n\n      // Get pose and detect body parts using the posenet model\n      const posenet = await posenet_model.estimateSinglePose(camera);\n      drawEmoticons(\n        posenet,\n        camera,\n        videoWidth,\n        videoHeight,\n        canvasEl,\n        EMOTICONS\n      );\n    }\n  };\n\n  const initPoseNet = async () => {\n    const model = await posenet.load({\n      inputResolution: INPUT_RESOLUTION,\n      scale: SCALE,\n    });\n\n    setInterval(() => {\n      detectPose(model);\n    }, REFRESH_RATE);\n  };\n\n  initPoseNet();\n\n  return (\n    <div className=\"App\">\n      <VideoCamera\n        videoRef={webcamEl}\n        constraints={{\n          video: {\n            facingMode,\n          },\n        }}\n      />\n      <canvas ref={canvasEl} />\n      <button onClick={handleCameraClick}>Flip cameras</button>\n    </div>\n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}